{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup before running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. download all 2019 data from \"https://webrobots.io/kickstarter-datasets/\"\n",
    "2. make a folder called \"raw_data\"\n",
    "3. within \"raw_data\" make 3 sub-folders with the date of the pulls in the format MM-DD-YYYY\n",
    "3. extract downloaded data into each of the 3 sub-folders appropriately\n",
    "4. in line 4 below change the \"path_master\" variable to your \"raw_data\" link\n",
    "5. run (~7min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge all csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "path_master = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4650 - Business Analytics/Project - Kickstarter Analysis/raw_data/'\n",
    "df_kickstarter = pd.DataFrame()\n",
    "\n",
    "def add_date(path):\n",
    "    return path[-10:-1]\n",
    "\n",
    "directories = list()\n",
    "for root, dirs, files in os.walk(path_master, topdown=False):\n",
    "    for name in dirs:\n",
    "        directories.append(os.path.join(root, name)+'/')\n",
    "\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path_master):\n",
    "    for filename in files:\n",
    "        if filename not in file_names: file_names.append(filename)\n",
    "\n",
    "for i in directories: \n",
    "    for j in file_names:\n",
    "        try:\n",
    "            with open(i+j, encoding='utf8') as fp:\n",
    "                df_interim = pd.read_csv(fp, keep_default_na=False)\n",
    "            df_interim['download_date'] = add_date(i)\n",
    "            df_interim['download_date'] = pd.to_datetime(df_interim['download_date'], format='%m-%d-%Y')\n",
    "            global df_kickstarter\n",
    "            df_kickstarter = pd.concat([df_kickstarter,df_interim])\n",
    "            print('SUCCESS: '+i+j)\n",
    "        except:\n",
    "            print('FAIL: '+i+j)\n",
    "            pass\n",
    "df_kickstarter.to_csv(path_master+'df_kickstarter'+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in random sample (10%) of full df_kickstarter to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "filename = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4650 - Business Analytics/Project - Kickstarter Analysis/raw_data/df_kickstarter.csv'\n",
    "\n",
    "p = 0.10  # 10% of the lines\n",
    "# keep the header, then take only 10% of lines\n",
    "# if random from [0,1] interval is greater than 0.10 the row will be skipped\n",
    "df = pd.read_csv(filename, header=0,  skiprows=lambda i: i>0 and random.random() > p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url scraping \n",
    "##### binary vars for: video, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(x):\n",
    "    return x.split(\"\\\"\")[5]\n",
    "\n",
    "df[\"urls\"] = df[\"urls\"].apply(lambda x: get_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
