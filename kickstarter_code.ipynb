{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup before running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. download all 2019 data from \"https://webrobots.io/kickstarter-datasets/\"\n",
    "2. make a folder called \"raw_data\"\n",
    "3. within \"raw_data\" make 3 sub-folders with the date of the pulls in the format MM-DD-YYYY\n",
    "3. extract downloaded data into each of the 3 sub-folders appropriately\n",
    "4. in line 4 below change the \"path_master\" variable to your \"raw_data\" link\n",
    "5. run (~7min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge all csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "path_master = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4650 - Business Analytics/Project - Kickstarter Analysis/raw_data/'\n",
    "df_kickstarter = pd.DataFrame()\n",
    "\n",
    "def add_date(path):\n",
    "    return path[-10:-1]\n",
    "\n",
    "directories = list()\n",
    "for root, dirs, files in os.walk(path_master, topdown=False):\n",
    "    for name in dirs:\n",
    "        directories.append(os.path.join(root, name)+'/')\n",
    "\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path_master):\n",
    "    for filename in files:\n",
    "        if filename not in file_names: file_names.append(filename)\n",
    "\n",
    "for i in directories: \n",
    "    for j in file_names:\n",
    "        try:\n",
    "            with open(i+j, encoding='utf8') as fp:\n",
    "                df_interim = pd.read_csv(fp, keep_default_na=False)\n",
    "            df_interim['download_date'] = add_date(i)\n",
    "            df_interim['download_date'] = pd.to_datetime(df_interim['download_date'], format='%m-%d-%Y')\n",
    "            global df_kickstarter\n",
    "            df_kickstarter = pd.concat([df_kickstarter,df_interim])\n",
    "            print('SUCCESS: '+i+j)\n",
    "        except:\n",
    "            print('FAIL: '+i+j)\n",
    "            pass\n",
    "df_kickstarter.to_csv(path_master+'df_kickstarter'+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in random sample (10%) of full df_kickstarter to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "filename = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4650 - Business Analytics/Project - Kickstarter Analysis/raw_data/df_kickstarter.csv'\n",
    "\n",
    "p = 0.05  # 5% of the lines\n",
    "# keep the header, then take only 5% of lines\n",
    "# if random from [0,1] interval is greater than 0.05 the row will be skipped\n",
    "df = pd.read_csv(filename, header=0,  skiprows=lambda i: i>0 and random.random() > p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(x):\n",
    "    return x.split(\"\\\"\")[5]\n",
    "\n",
    "df[\"urls\"] = df[\"urls\"].apply(lambda x: get_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import datetime\n",
    "\n",
    "def add_fundpd(x,y):\n",
    "    user_agent_list = [\n",
    "           #Chrome\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            #Firefox\n",
    "            'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "            'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "        ]\n",
    "    user_agent = random.choice(user_agent_list)\n",
    "    heads = {'User-Agent': user_agent}\n",
    "    time.sleep(7)\n",
    "    \n",
    "    page = requests.get(x,headers=heads)\n",
    "    results_page = BeautifulSoup(page.content,'lxml')\n",
    "    period = results_page.find('div',class_='NS_campaigns__funding_period').find_all(class_=\"js-adjust-time\")\n",
    "    start = pd.to_datetime(period[0].get_text(), format='%b %d, %Y').strftime('%Y-%m-%d')\n",
    "    end = pd.to_datetime(period[1].get_text(), format='%b %d, %Y').strftime('%Y-%m-%d')\n",
    "    if y==\"start\": return start\n",
    "    if y==\"end\": return end\n",
    "    \n",
    "df[\"funding_start\"] = df[\"urls\"].apply(lambda x: add_fund_start(x,'start'))\n",
    "df[\"funing_end\"] = df[\"urls\"].apply(lambda x: add_fund_start(x,'end'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [i for i in df[\"urls\"]]\n",
    "link = urls[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
